{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data\n",
      "Unzipping data\n"
     ]
    }
   ],
   "source": [
    "from get_data import get_data\n",
    "\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATASET_PATH = \"data/UCI HAR Dataset/\"\n",
    "TRAIN = \"train/\"\n",
    "TEST = \"test/\"\n",
    "INPUT_TYPES = [\n",
    "    \"body_acc_x_\",\n",
    "    \"body_acc_y_\",\n",
    "    \"body_acc_z_\",\n",
    "    \"body_gyro_x_\",\n",
    "    \"body_gyro_y_\",\n",
    "    \"body_gyro_z_\",\n",
    "    \"total_acc_x_\",\n",
    "    \"total_acc_y_\",\n",
    "    \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "X_train = np.dstack([\n",
    "    pd.read_csv(DATASET_PATH + TRAIN + \"Inertial Signals/\" + signal + \"train.txt\", header=None, delim_whitespace=True).values for signal in INPUT_TYPES\n",
    "])\n",
    "X_test = np.dstack([\n",
    "    pd.read_csv(DATASET_PATH + TEST + \"Inertial Signals/\" + signal + \"test.txt\", header=None, delim_whitespace=True).values for signal in INPUT_TYPES\n",
    "])\n",
    "\n",
    "y_raw_train = pd.read_csv(DATASET_PATH + TRAIN + \"y_train.txt\", header=None, delim_whitespace=True).values\n",
    "y_raw_test = pd.read_csv(DATASET_PATH + TEST + \"y_test.txt\", header=None, delim_whitespace=True).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "y_train = encoder.fit_transform(y_raw_train).toarray()\n",
    "y_test = encoder.transform(y_raw_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(7352, 128, 9) (7352, 6) 0.10206605723804434 0.4021651763827929\n",
      "(2947, 128, 9) (2947, 6) 0.09913989069610848 0.39567084061541474\n",
      "The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_train.shape, y_train.shape, np.mean(X_train), np.std(X_train))\n",
    "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-26 17:37:58.681630: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-26 17:37:58.688533: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fca65f20d70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-26 17:37:58.688548: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Host, Default Version\n",
      "2021-08-26 17:37:58.784258: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "230/230 [==============================] - 20s 74ms/step - loss: 1.2802 - accuracy: 0.5760 - val_loss: 1.0598 - val_accuracy: 0.6474\n",
      "Epoch 2/30\n",
      "230/230 [==============================] - 17s 73ms/step - loss: 0.8585 - accuracy: 0.7257 - val_loss: 0.9233 - val_accuracy: 0.6973\n",
      "Epoch 3/30\n",
      "230/230 [==============================] - 17s 76ms/step - loss: 0.8508 - accuracy: 0.7247 - val_loss: 1.0297 - val_accuracy: 0.6614\n",
      "Epoch 4/30\n",
      "230/230 [==============================] - 17s 75ms/step - loss: 0.8906 - accuracy: 0.7137 - val_loss: 0.9640 - val_accuracy: 0.6787\n",
      "Epoch 5/30\n",
      "230/230 [==============================] - 17s 74ms/step - loss: 0.7745 - accuracy: 0.7644 - val_loss: 0.9495 - val_accuracy: 0.6960\n",
      "Epoch 6/30\n",
      "230/230 [==============================] - 17s 73ms/step - loss: 0.6594 - accuracy: 0.8192 - val_loss: 0.8314 - val_accuracy: 0.7679\n",
      "Epoch 7/30\n",
      "230/230 [==============================] - 17s 75ms/step - loss: 0.5634 - accuracy: 0.8779 - val_loss: 0.8404 - val_accuracy: 0.7808\n",
      "Epoch 8/30\n",
      "230/230 [==============================] - 17s 74ms/step - loss: 0.5119 - accuracy: 0.9045 - val_loss: 0.7535 - val_accuracy: 0.8293\n",
      "Epoch 9/30\n",
      "230/230 [==============================] - 17s 74ms/step - loss: 0.4556 - accuracy: 0.9280 - val_loss: 0.7070 - val_accuracy: 0.8544\n",
      "Epoch 10/30\n",
      "230/230 [==============================] - 17s 73ms/step - loss: 0.4030 - accuracy: 0.9427 - val_loss: 0.7128 - val_accuracy: 0.8582\n",
      "Epoch 11/30\n",
      "230/230 [==============================] - 17s 74ms/step - loss: 0.3874 - accuracy: 0.9438 - val_loss: 0.7390 - val_accuracy: 0.8541\n",
      "Epoch 12/30\n",
      "230/230 [==============================] - 17s 74ms/step - loss: 0.3702 - accuracy: 0.9471 - val_loss: 0.8427 - val_accuracy: 0.8249\n",
      "Epoch 13/30\n",
      "230/230 [==============================] - 17s 75ms/step - loss: 0.3672 - accuracy: 0.9474 - val_loss: 0.7140 - val_accuracy: 0.8548\n",
      "Epoch 14/30\n",
      "230/230 [==============================] - 17s 74ms/step - loss: 0.3613 - accuracy: 0.9470 - val_loss: 0.7125 - val_accuracy: 0.8493\n",
      "Epoch 15/30\n",
      "230/230 [==============================] - 17s 75ms/step - loss: 0.3365 - accuracy: 0.9523 - val_loss: 0.7824 - val_accuracy: 0.8419\n",
      "Epoch 16/30\n",
      "230/230 [==============================] - 18s 77ms/step - loss: 0.3385 - accuracy: 0.9460 - val_loss: 0.7957 - val_accuracy: 0.8300\n",
      "Epoch 17/30\n",
      "230/230 [==============================] - 17s 76ms/step - loss: 0.3455 - accuracy: 0.9475 - val_loss: 0.5811 - val_accuracy: 0.8734\n",
      "Epoch 18/30\n",
      "230/230 [==============================] - 18s 77ms/step - loss: 0.4097 - accuracy: 0.9280 - val_loss: 0.7637 - val_accuracy: 0.8341\n",
      "Epoch 19/30\n",
      "230/230 [==============================] - 18s 77ms/step - loss: 0.4222 - accuracy: 0.9202 - val_loss: 0.7374 - val_accuracy: 0.8385\n",
      "Epoch 20/30\n",
      "230/230 [==============================] - 20s 87ms/step - loss: 0.3457 - accuracy: 0.9431 - val_loss: 0.7351 - val_accuracy: 0.8602\n",
      "Epoch 21/30\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.3502 - accuracy: 0.9407 - val_loss: 0.6889 - val_accuracy: 0.8629\n",
      "Epoch 22/30\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.3250 - accuracy: 0.9495 - val_loss: 0.6339 - val_accuracy: 0.8677\n",
      "Epoch 23/30\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.3662 - accuracy: 0.9343 - val_loss: 0.6920 - val_accuracy: 0.8578\n",
      "Epoch 24/30\n",
      "230/230 [==============================] - 26s 115ms/step - loss: 0.3261 - accuracy: 0.9422 - val_loss: 0.6794 - val_accuracy: 0.8612\n",
      "Epoch 25/30\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.3181 - accuracy: 0.9486 - val_loss: 0.7644 - val_accuracy: 0.8347\n",
      "Epoch 26/30\n",
      "230/230 [==============================] - 25s 111ms/step - loss: 0.3184 - accuracy: 0.9457 - val_loss: 0.5873 - val_accuracy: 0.8687\n",
      "Epoch 27/30\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.2975 - accuracy: 0.9528 - val_loss: 0.6360 - val_accuracy: 0.8700\n",
      "Epoch 28/30\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.2879 - accuracy: 0.9523 - val_loss: 0.6470 - val_accuracy: 0.8595\n",
      "Epoch 29/30\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.3239 - accuracy: 0.9389 - val_loss: 0.8990 - val_accuracy: 0.7838\n",
      "Epoch 30/30\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.3101 - accuracy: 0.9437 - val_loss: 0.6636 - val_accuracy: 0.8616\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "l2_value = 0.0015\n",
    "\n",
    "lstm = models.Sequential([\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l2(l2_value), bias_regularizer=l2(l2_value)),\n",
    "    layers.LSTM(32, input_shape=(128, 9), return_sequences=True, kernel_regularizer=l2(l2_value), bias_regularizer=l2(l2_value), recurrent_regularizer=l2(l2_value)),\n",
    "    layers.LSTM(32, kernel_regularizer=l2(l2_value), bias_regularizer=l2(l2_value), recurrent_regularizer=l2(l2_value)),\n",
    "    layers.Dense(6, activation=\"softmax\", kernel_regularizer=l2(l2_value), bias_regularizer=l2(l2_value))\n",
    "])\n",
    "\n",
    "lstm.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = lstm.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1243271c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_train, data_test = data.get_datasets()\n",
    "plt.imshow(data_train[2][0].squeeze(), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self._flatten = nn.Flatten()\n",
    "        self._model = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "        self._flatten.requires_grad_(False)\n",
    "        self._model.requires_grad_(False)\n",
    "        self.requires_grad_(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(self._flatten(x))\n",
    "\n",
    "    def child(self, std_dev: float) -> 'Model':\n",
    "        child = deepcopy(self)\n",
    "        for p in self.parameters():\n",
    "            p.add_(torch.randn(p.size()) * std_dev)\n",
    "        return child\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List\n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "loss_function.requires_grad_(False)\n",
    "num_parents = 4\n",
    "mutation_per_parent = 4\n",
    "std_dev = 0.1\n",
    "\n",
    "\n",
    "def train(candidates: List[Model]):\n",
    "    X = data_train.data\n",
    "    y = data_train.targets\n",
    "    candidates.extend(\n",
    "        [parent.child(std_dev) for parent in candidates for _ in range(mutation_per_parent)]\n",
    "    )\n",
    "    eval_candidates = [(candidate, loss_function(candidate(X), y).item()) for candidate in candidates]\n",
    "    eval_candidates.sort(key=lambda c: c[1])\n",
    "\n",
    "    candidates = list(map(lambda c: c[0], eval_candidates[0:num_parents]))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model: Model):\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    X = data_test.data\n",
    "    y = data_test.targets\n",
    "    pred = model(X)\n",
    "    test_loss = loss_function(pred, y).item()\n",
    "    accuracy += (torch.argmax(pred, dim=1) == torch.argmax(y, dim=1)).type(torch.float).mean()\n",
    "    tqdm.write(f\"Test -> Loss: {test_loss}, accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7222720602e24f46a95e4df39a8884cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000003?line=5'>6</a>\u001b[0m candidates \u001b[39m=\u001b[39m [Model() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_parents)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000003?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, \u001b[39m2001\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000003?line=8'>9</a>\u001b[0m     candidates \u001b[39m=\u001b[39m train(candidates)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000003?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000003?line=10'>11</a>\u001b[0m         model \u001b[39m=\u001b[39m candidates[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb Cell 3'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(candidates)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=14'>15</a>\u001b[0m y \u001b[39m=\u001b[39m data_train\u001b[39m.\u001b[39mtargets\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=15'>16</a>\u001b[0m candidates\u001b[39m.\u001b[39mextend(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=16'>17</a>\u001b[0m     [parent\u001b[39m.\u001b[39mchild(std_dev) \u001b[39mfor\u001b[39;00m parent \u001b[39min\u001b[39;00m candidates \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(mutation_per_parent)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=17'>18</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=18'>19</a>\u001b[0m eval_candidates \u001b[39m=\u001b[39m [(candidate, loss_function(candidate(X), y)\u001b[39m.\u001b[39mitem()) \u001b[39mfor\u001b[39;00m candidate \u001b[39min\u001b[39;00m candidates]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=19'>20</a>\u001b[0m eval_candidates\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m c: c[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=21'>22</a>\u001b[0m candidates \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m c: c[\u001b[39m0\u001b[39m], eval_candidates[\u001b[39m0\u001b[39m:num_parents]))\n",
      "\u001b[1;32m/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb Cell 3'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=14'>15</a>\u001b[0m y \u001b[39m=\u001b[39m data_train\u001b[39m.\u001b[39mtargets\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=15'>16</a>\u001b[0m candidates\u001b[39m.\u001b[39mextend(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=16'>17</a>\u001b[0m     [parent\u001b[39m.\u001b[39mchild(std_dev) \u001b[39mfor\u001b[39;00m parent \u001b[39min\u001b[39;00m candidates \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(mutation_per_parent)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=17'>18</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=18'>19</a>\u001b[0m eval_candidates \u001b[39m=\u001b[39m [(candidate, loss_function(candidate(X), y)\u001b[39m.\u001b[39mitem()) \u001b[39mfor\u001b[39;00m candidate \u001b[39min\u001b[39;00m candidates]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=19'>20</a>\u001b[0m eval_candidates\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m c: c[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000002?line=21'>22</a>\u001b[0m candidates \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m c: c[\u001b[39m0\u001b[39m], eval_candidates[\u001b[39m0\u001b[39m:num_parents]))\n",
      "File \u001b[0;32m~/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb Cell 2'\u001b[0m in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000001?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/thomaszub/projects/machine-learning/ml-playground/MNIST/evolutional.ipynb#ch0000001?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flatten(x))\n",
      "File \u001b[0;32m~/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///Users/thomaszub/projects/machine-learning/ml-playground/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Byte"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "torch.manual_seed(666)\n",
    "candidates = [Model() for _ in range(num_parents)]\n",
    "\n",
    "for epoch in trange(1, 2001, desc=\"Epoch\"):\n",
    "    candidates = train(candidates)\n",
    "    if epoch % 100 == 0:\n",
    "        model = candidates[0]\n",
    "        test(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6054d1dd935479306a74e50f347ede3643b15d93710fd47fc25576ff2d42d53"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
